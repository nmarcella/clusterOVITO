{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ovito\n",
    "from ovito.io import import_file\n",
    "from ovito.modifiers import *\n",
    "from ovito.data import *\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "from clusterOVITO.basic.io import *\n",
    "from clusterOVITO.basic.xyz_to_FEFF import *\n",
    "from clusterOVITO.ovito_tools import *  \n",
    "from ovito.modifiers import ReplicateModifier\n",
    "\n",
    "\n",
    "from clusterOVITO.basic.xyz_to_FEFF import *\n",
    "\n",
    "rmeshPrime = np.arange(0.01, 6, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MD_EXAFS_Binary_Pipeline:\n",
    "    def __init__(self, pipeline, framerange, file_params):\n",
    "        self.pipeline = pipeline\n",
    "        self.framerange = framerange\n",
    "        self.file_params = file_params\n",
    "        #self.proj_name = file_params[\"proj_name\"]\n",
    "        #self.working_dir = file_params[\"working_dir\"]\n",
    "        #self.cluster_dir = file_params[\"cluster_dir\"]\n",
    "        #self.proj_dir = self.working_dir + self.proj_name + '/'\n",
    "        self.frame = 0\n",
    "        self.interesting_c = 0\n",
    "        self.interesting_pt = 0\n",
    "        self.all_pt = 0\n",
    "        self.interesting_o = 0\n",
    "        self.b_line_table = []\n",
    "\n",
    "    def run(self):\n",
    "        for frame in self.framerange:\n",
    "            self.frame = frame\n",
    "            data = self.pipeline.compute(frame)\n",
    "            finder = CutoffNeighborFinder(3, data)\n",
    "\n",
    "            ptatom_index, catom_index, oatom_index = self.get_atom_indices(data)\n",
    "            all_positions = data.particles.positions[...]\n",
    "\n",
    "            interesting_c, interesting_pt, interesting_o = self.find_interesting_atoms(\n",
    "                catom_index, ptatom_index, oatom_index, finder\n",
    "            )\n",
    "\n",
    "            self.interesting_c = all_positions[interesting_c]\n",
    "            self.interesting_pt = all_positions[interesting_pt]\n",
    "            self.interesting_o = all_positions[interesting_o]\n",
    "            self.all_pt = all_positions[ptatom_index]\n",
    "\n",
    "            self.add_sep_line_start()\n",
    "            self.make_files()\n",
    "        self.finish()\n",
    "\n",
    "\n",
    "    def get_atom_indices(self, data):\n",
    "        ptatom_index = np.where(data.particles['Particle Type'].array == 1)[0]\n",
    "        catom_index = np.where(data.particles['Particle Type'].array == 2)[0]\n",
    "        oatom_index = np.where(data.particles['Particle Type'].array == 3)[0]\n",
    "        return ptatom_index, catom_index, oatom_index\n",
    "\n",
    "    def find_interesting_atoms(self, catom_index, ptatom_index, oatom_index, finder):\n",
    "        interesting_c, interesting_pt, interesting_o = [], [], []\n",
    "        for i in catom_index:\n",
    "            neigh = [neigh.index for neigh in finder.find(i)]\n",
    "            if len(neigh) > 0:\n",
    "                n_count = 0\n",
    "                for l in neigh:\n",
    "                    if l in ptatom_index:\n",
    "                        n_count += 1\n",
    "                        interesting_pt.append(l)\n",
    "                if n_count > 0:\n",
    "                    interesting_c.append(i)\n",
    "\n",
    "        interesting_c = np.unique(np.array(interesting_c))\n",
    "        interesting_pt = np.unique(np.array(interesting_pt))\n",
    "\n",
    "        for i in interesting_c:\n",
    "            neigh = [neigh.index for neigh in finder.find(i)]\n",
    "            if len(neigh) > 0:\n",
    "                for l in neigh:\n",
    "                    if l in oatom_index:\n",
    "                        interesting_o.append(l)\n",
    "\n",
    "        interesting_o = np.unique(np.array(interesting_o))\n",
    "\n",
    "        return interesting_c, interesting_pt, interesting_o\n",
    "    \n",
    "    def make_files(self):\n",
    "        n_c = self.interesting_c.shape[0]\n",
    "        n_pt = self.all_pt.shape[0]\n",
    "        n_o = self.interesting_o.shape[0]\n",
    "\n",
    "        n_pt_pot = 1\n",
    "        n_c_pot = 2\n",
    "        n_o_pot = 3\n",
    "\n",
    "        n_pt_pots = np.full(n_pt, 1).reshape(-1, 1)\n",
    "        pt_lattice = np.concatenate((self.all_pt, n_pt_pots), axis=1)\n",
    "        \n",
    "        n_c_pots = np.full(n_c, 2).reshape(-1, 1)\n",
    "        c_lattice = np.concatenate((self.interesting_c, n_c_pots), axis=1)\n",
    "\n",
    "        n_o_pots = np.full(n_o, 3).reshape(-1, 1)\n",
    "        o_lattice = np.concatenate((self.interesting_o, n_o_pots), axis=1)\n",
    "        \n",
    "\n",
    "        b_line = np.concatenate((pt_lattice, c_lattice, o_lattice), axis=0)\n",
    "        b_line = np.around(b_line, decimals=4)\n",
    "        self.b_line_table.append(b_line)\n",
    "\n",
    "\n",
    "    def add_sep_line_start(self):\n",
    "        self.b_line_table.append(np.array([[0,0,0,0]]))\n",
    "\n",
    "    def add_sep_line_end(self):\n",
    "        self.b_line_table.append(np.array([1,1,1,1]))\n",
    "\n",
    "    def finish(self):\n",
    "        self.data = np.concatenate(self.b_line_table, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Make input table and export\n",
    "###\n",
    "\n",
    "import struct\n",
    "import io\n",
    "import tarfile\n",
    "\n",
    "###########################################\n",
    "\n",
    "traj_dir = '/mnt/a/MD_Trajectories/PtCO/NPs/'\n",
    "traj_name = \"Pt309_cuboct_298K.all.bin\"\n",
    "\n",
    "p_name = \"Pt309_cuboct_298K\"\n",
    "#input_dir = \"/mnt/a/MD_Trajectories/PtCO/NPs/Inputs/\"\n",
    "input_dir = \"/mnt/sdcc/sdcc+u/nmarcella/MD_EXAFS_inputs/231228/\"\n",
    "\n",
    "\n",
    "###########################################\n",
    "traj_path = traj_dir + traj_name\n",
    "\n",
    "dir_name = input_dir + p_name + \"/\"\n",
    "\n",
    "# if it doesn't exist, make it\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "file_name = p_name + \".bin\"\n",
    "tar_name = file_name + \".tar.gz\"\n",
    "\n",
    "\n",
    "pipeline = import_file(traj_path)\n",
    "\n",
    "test_pl = MD_EXAFS_Binary_Pipeline(pipeline, range(15999,18000), file_params={})\n",
    "test_pl.run()\n",
    "\n",
    "data = test_pl.data\n",
    "\n",
    "###########################################\n",
    "\n",
    "# Create a BytesIO object to accumulate the binary data\n",
    "binary_buffer = io.BytesIO()\n",
    "\n",
    "# Assuming 'data' is a 2D array where each row is [x, y, z, p]\n",
    "for line in data:\n",
    "    # Extract x, y, z, and p from the line\n",
    "    x, y, z, p = line[0], line[1], line[2], int(line[3])\n",
    "\n",
    "    # Pack the data into a binary format and write to the BytesIO object\n",
    "    binary_data = struct.pack(\"fffI\", x, y, z, p)\n",
    "    binary_buffer.write(binary_data)\n",
    "\n",
    "# Rewind the buffer to the beginning\n",
    "binary_buffer.seek(0)\n",
    "\n",
    "# Create a .tar.gz file and add the BytesIO object\n",
    "tar_file_name = dir_name + tar_name\n",
    "with tarfile.open(tar_file_name, \"w:gz\") as tar:\n",
    "    # Create a TarInfo object for the BytesIO object\n",
    "    info = tarfile.TarInfo(name=file_name)\n",
    "    info.size = len(binary_buffer.getbuffer())\n",
    "    \n",
    "    # Add the BytesIO object to the tar archive\n",
    "    tar.addfile(tarinfo=info, fileobj=binary_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = import_file(traj_path)\n",
    "\n",
    "test_pl = MD_EXAFS_Binary_Pipeline(pipeline, range(15999,16000), file_params={})\n",
    "test_pl.run()\n",
    "\n",
    "data = test_pl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"Pt\":1, \"C\":2, \"O\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MD_EXAFS_Binary_Pipeline_General:\n",
    "    def __init__(self, pipeline, file_params, custom_analysis_func=None):\n",
    "        self.pipeline = pipeline\n",
    "        self.framerange = file_params[\"framerange\"]\n",
    "        self.atoms = file_params[\"atoms\"]\n",
    "        self.cutoff = file_params[\"cutoff\"]\n",
    "        self.custom_analysis_func = custom_analysis_func\n",
    "        self.b_line_table = []\n",
    "\n",
    "    def run(self):\n",
    "        for frame in self.framerange:\n",
    "            self.frame = frame\n",
    "            data = self.pipeline.compute(frame)\n",
    "            finder = CutoffNeighborFinder(self.cutoff, data)\n",
    "\n",
    "            atomic_position_index_list = self.get_atom_indices(data)\n",
    "            all_positions = data.particles.positions[...]\n",
    "\n",
    "            if self.custom_analysis_func:\n",
    "            \n",
    "                custom_result = self.custom_analysis_func(\n",
    "                    atomic_position_index_list, finder\n",
    "                    )\n",
    "                self.interesting_results = []\n",
    "                # add metal first\n",
    "                self.interesting_results.append(all_positions[atomic_position_index_list[0]])\n",
    "                # add other atoms\n",
    "                for result in custom_result:\n",
    "                    self.interesting_results.append(all_positions[result])\n",
    "            # just add metal\n",
    "            else:\n",
    "                self.interesting_results = [all_positions[atomic_position_index_list[0]]]\n",
    "\n",
    "            self.add_sep_line_start()\n",
    "\n",
    "            self.make_files()\n",
    "\n",
    "        self.finish()\n",
    "\n",
    "    def get_atom_indices(self, data):\n",
    "\n",
    "        atomic_position_index_list = []\n",
    "        for atom in self.atoms.values():\n",
    "            atomic_position_index_list.append(np.where(data.particles['Particle Type'].array == atom)[0])\n",
    "\n",
    "        return atomic_position_index_list\n",
    "    \n",
    "\n",
    "    def make_lattice(self, n_atoms, n_pot, atom_coords):\n",
    "            n_pots = np.full(n_atoms, n_pot).reshape(-1, 1)\n",
    "            lattice = np.concatenate((atom_coords, n_pots), axis=1)\n",
    "            return lattice\n",
    "\n",
    "    def make_files(self):\n",
    "        \n",
    "        n_atoms = [atom.shape[0] for atom in self.interesting_results]\n",
    "        \n",
    "        atom_pots = [pot for pot in self.atoms.values()]\n",
    "\n",
    "        lattices = [self.make_lattice(n_atom, n_pot, atom_coords) for n_atom, n_pot, atom_coords in zip(n_atoms, atom_pots, self.interesting_results)]\n",
    "\n",
    "        b_line = np.concatenate(lattices, axis=0)\n",
    "        b_line = np.around(b_line, decimals=4)\n",
    "        self.b_line_table.append(b_line)\n",
    "\n",
    "\n",
    "    def add_sep_line_start(self):\n",
    "        self.b_line_table.append(np.array([[0,0,0,0]]))\n",
    "\n",
    "    def add_sep_line_end(self):\n",
    "        self.b_line_table.append(np.array([1,1,1,1]))\n",
    "\n",
    "    def finish(self):\n",
    "        self.data = np.concatenate(self.b_line_table, axis=0)\n",
    "\n",
    "\n",
    "def find_adsorbed_CO(atomic_position_index_list, finder):\n",
    "        ptatom_index, catom_index, oatom_index = atomic_position_index_list\n",
    "        interesting_c, interesting_pt, interesting_o = [], [], []\n",
    "        for i in catom_index:\n",
    "            neigh = [neigh.index for neigh in finder.find(i)]\n",
    "            if len(neigh) > 0:\n",
    "                n_count = 0\n",
    "                for l in neigh:\n",
    "                    if l in ptatom_index:\n",
    "                        n_count += 1\n",
    "                        interesting_pt.append(l)\n",
    "                if n_count > 0:\n",
    "                    interesting_c.append(i)\n",
    "\n",
    "        interesting_c = np.unique(np.array(interesting_c))\n",
    "        interesting_pt = np.unique(np.array(interesting_pt))\n",
    "\n",
    "        for i in interesting_c:\n",
    "            neigh = [neigh.index for neigh in finder.find(i)]\n",
    "            if len(neigh) > 0:\n",
    "                for l in neigh:\n",
    "                    if l in oatom_index:\n",
    "                        interesting_o.append(l)\n",
    "\n",
    "        interesting_o = np.unique(np.array(interesting_o))\n",
    "\n",
    "        return interesting_c, interesting_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "traj_dir = '/mnt/a/MD_Trajectories/PtCO/NPs/'\n",
    "traj_name = \"Pt309_cuboct_298K.all.bin\"\n",
    "\n",
    "p_name = \"Pt309_cuboct_298K\"\n",
    "#input_dir = \"/mnt/a/MD_Trajectories/PtCO/NPs/Inputs/\"\n",
    "input_dir = \"/mnt/sdcc/sdcc+u/nmarcella/MD_EXAFS_inputs/231228/\"\n",
    "\n",
    "\n",
    "###########################################\n",
    "traj_path = traj_dir + traj_name\n",
    "\n",
    "pipeline = import_file(traj_path)\n",
    "\n",
    "#test_pl = MD_EXAFS_Binary_Pipeline_General(pipeline, file_params={\"framerange\": range(15999,16000),\"atoms\":{\"Pt\":1, \"C\":2, \"O\":3}, \"cutoff\":3}, custom_analysis_func=find_adsorbed_CO)\n",
    "test_pl = MD_EXAFS_Binary_Pipeline_General(pipeline, file_params={\"framerange\": range(15999,16000),\"atoms\":{\"Pt\":1}, \"cutoff\":3})\n",
    "test_pl.run()\n",
    "\n",
    "data = test_pl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Make input table and export\n",
    "###\n",
    "\n",
    "import struct\n",
    "import io\n",
    "import tarfile\n",
    "\n",
    "###########################################\n",
    "\n",
    "traj_dir = '/mnt/a/MD_Trajectories/PtCO/NPs/'\n",
    "traj_name = \"Pt309_cuboct_298K.all.bin\"\n",
    "\n",
    "p_name = \"Pt309_cuboct_298K_noCO\"\n",
    "#input_dir = \"/mnt/a/MD_Trajectories/PtCO/NPs/Inputs/\"\n",
    "input_dir = \"/mnt/sdcc/sdcc+u/nmarcella/MD_EXAFS_inputs/231228/\"\n",
    "\n",
    "\n",
    "###########################################\n",
    "traj_path = traj_dir + traj_name\n",
    "\n",
    "dir_name = input_dir + p_name + \"/\"\n",
    "\n",
    "# if it doesn't exist, make it\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "file_name = p_name + \".bin\"\n",
    "tar_name = file_name + \".tar.gz\"\n",
    "\n",
    "\n",
    "pipeline = import_file(traj_path)\n",
    "\n",
    "test_pl = MD_EXAFS_Binary_Pipeline_General(pipeline, file_params={\"framerange\": range(15999,18000),\"atoms\":{\"Pt\":1}, \"cutoff\":3})\n",
    "test_pl.run()\n",
    "\n",
    "data = test_pl.data\n",
    "\n",
    "###########################################\n",
    "\n",
    "# Create a BytesIO object to accumulate the binary data\n",
    "binary_buffer = io.BytesIO()\n",
    "\n",
    "# Assuming 'data' is a 2D array where each row is [x, y, z, p]\n",
    "for line in data:\n",
    "    # Extract x, y, z, and p from the line\n",
    "    x, y, z, p = line[0], line[1], line[2], int(line[3])\n",
    "\n",
    "    # Pack the data into a binary format and write to the BytesIO object\n",
    "    binary_data = struct.pack(\"fffI\", x, y, z, p)\n",
    "    binary_buffer.write(binary_data)\n",
    "\n",
    "# Rewind the buffer to the beginning\n",
    "binary_buffer.seek(0)\n",
    "\n",
    "# Create a .tar.gz file and add the BytesIO object\n",
    "tar_file_name = dir_name + tar_name\n",
    "with tarfile.open(tar_file_name, \"w:gz\") as tar:\n",
    "    # Create a TarInfo object for the BytesIO object\n",
    "    info = tarfile.TarInfo(name=file_name)\n",
    "    info.size = len(binary_buffer.getbuffer())\n",
    "    \n",
    "    # Add the BytesIO object to the tar archive\n",
    "    tar.addfile(tarinfo=info, fileobj=binary_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/sdcc/sdcc+u/nmarcella/MD_EXAFS_inputs/231228/Pt309_cuboct_298K_noCO/'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OVITO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
